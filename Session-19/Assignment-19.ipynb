{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "GVY3XJhuhvkg",
    "outputId": "3344865b-7c31-4282-d6cb-882af5de3e2e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    os.chdir('/content')\n",
    "    if not os.path.isdir('/content/EVA-2-Group/'):\n",
    "        !git clone https://github.com/sambitdash/EVA-2-Group.git\n",
    "    os.chdir('/content/EVA-2-Group/Session-19')\n",
    "    !pwd\n",
    "    \n",
    "    !git config user.email \"sambitdash@gmail.com\"\n",
    "    !git config user.name \"Sambit Kumar Dash\"\n",
    "    !git config user.password \"your password\"\n",
    "    !git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "BbhSFX9Jhvkl",
    "outputId": "c4a40efa-9706-4279-f048-5bebb513c149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 64, 64, 3)\n",
      "(410, 64, 64, 3)\n",
      "(337, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "car_types = ['hatch', 'sedan', 'suv']\n",
    "\n",
    "def resize_image(img, size=(64,64)):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if h == w: \n",
    "        return cv2.resize(img, size, cv2.INTER_AREA)\n",
    "\n",
    "    dif = h if h > w else w\n",
    "\n",
    "    interpolation = cv2.INTER_AREA if dif > (size[0]+size[1])//2 else cv2.INTER_CUBIC\n",
    "\n",
    "    x_pos = (dif - w)//2\n",
    "    y_pos = (dif - h)//2\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
    "    else:\n",
    "        c = img.shape[2]\n",
    "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
    "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
    "\n",
    "    return cv2.resize(mask, size, interpolation)\n",
    "\n",
    "spath, dpath = join('data', 'cars'), join('data', 'norm')\n",
    "\n",
    "if not os.path.isdir(dpath):\n",
    "    os.mkdir(dpath)\n",
    "\n",
    "imgs = {}\n",
    "\n",
    "\n",
    "for ct in car_types:\n",
    "    sp, dp = join(spath, ct), join(dpath, ct)\n",
    "    alen = 1024\n",
    "    imgs[ct] = np.zeros((1024, 64, 64, 3))\n",
    "    if not os.path.isdir(dp):\n",
    "        os.mkdir(dp)\n",
    "    tlen = 0\n",
    "    for f in listdir(sp):\n",
    "        sf, df = join(sp, f), join(dp, f)\n",
    "        img = cv2.imread(sf)\n",
    "        img = resize_image(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        tlen += 1\n",
    "        if tlen > alen:\n",
    "            imgs[ct] = np.append(imgs[ct], np.zeros((1024, 64, 64, 3)))\n",
    "            alen += 1024\n",
    "        imgs[ct][tlen-1] = img\n",
    "    imgs[ct] = imgs[ct][:tlen]\n",
    "    print(imgs[ct].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "xgWY9ontMgFW",
    "outputId": "1b1466f1-116e-441b-9ccf-d19252b1719e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sambit/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "(675, 64, 64, 3) y (675,)\n",
      "(67, 64, 64, 3) y (67,)\n",
      "(675, 64, 64, 3) y (675,)\n",
      "(67, 64, 64, 3) y (67,)\n",
      "[0.35301414 0.34561545 0.34175763] [0.3740168  0.37273017 0.37292084]\n",
      "-0.9438457 1.7650994\n",
      "-0.9438457 1.7650994\n",
      "(675, 64, 64, 3) (675,)\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 1.x\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "\n",
    "from tensorflow.keras import utils \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "trainx, testx = imgs['hatch'][:300,:,:,:], imgs['hatch'][300:,:,:,:]\n",
    "\n",
    "trainy, testy = np.zeros(trainx.shape[0], dtype=float), np.zeros(testx.shape[0], dtype=float)\n",
    "\n",
    "trainx = np.append(trainx, imgs['sedan'][:375,:,:,:], axis=0)\n",
    "testx = np.append(testx, imgs['sedan'][375:,:,:,:], axis=0)\n",
    "\n",
    "ltrain, ltest = trainx.shape[0] - trainy.shape[0], testx.shape[0] - testy.shape[0]\n",
    "\n",
    "trainy, testy = np.append(trainy, np.ones(ltrain, dtype=float)), np.append(testy, np.ones(ltest, dtype=float))\n",
    "\n",
    "\n",
    "print(trainx.shape, \"y\", trainy.shape)\n",
    "print(testx.shape, 'y', testy.shape)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(trainx)\n",
    "\n",
    "trainX, trainY = trainx, trainy\n",
    "testX, testY   = testx, testy\n",
    "\n",
    "for i in range(0):\n",
    "    iterate = datagen.flow(trainx, trainy, batch_size=len(trainx), shuffle=True)\n",
    "    x, y = iterate.next()\n",
    "    trainX, trainY = np.append(trainX, x, axis=0), np.append(trainY, y, axis=0)\n",
    "\n",
    "for i in range(0):\n",
    "    iterate = datagen.flow(testx, testy, batch_size=len(testx), shuffle=True)\n",
    "    x, y = iterate.next()\n",
    "    testX, testY = np.append(testX, x, axis=0), np.append(testY, y, axis=0)\n",
    "\n",
    "\n",
    "print(trainX.shape, \"y\", trainY.shape)\n",
    "print(testX.shape, \"y\", testY.shape)\n",
    "\n",
    "trainx, trainy = trainX, trainY\n",
    "testx, testy   = testX, testY\n",
    "\n",
    "trainx = trainx.astype('float32') / 255\n",
    "testx  = testx.astype('float32') / 255\n",
    "\n",
    "trainx_mean = np.mean(trainx, axis=(0, 1, 2))\n",
    "trainx_std  = np.std(trainx, axis=(0, 1, 2))\n",
    "\n",
    "print(trainx_mean, trainx_std)\n",
    "\n",
    "trainx -= trainx_mean\n",
    "trainx /= trainx_std\n",
    "\n",
    "testx -= trainx_mean\n",
    "testx /= trainx_std\n",
    "\n",
    "trainX, trainY = trainx, trainy #utils.to_binary(trainy)\n",
    "testX,  testY  = testx,  testy  #utils.to_binary(testy)\n",
    "\n",
    "min_pix, max_pix = trainX.min(), trainX.max()\n",
    "\n",
    "print(min_pix, max_pix)\n",
    "print(testX.min(), testX.max())\n",
    "\n",
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "K-vi5P3dSZBh",
    "outputId": "78a61916-8818-44c5-8ddf-9c2a7db96b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ik_4kxmzJGoo"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation, MaxPool2D\n",
    "from tensorflow.keras.layers import add, Input, Dense, Flatten, GlobalAvgPool2D, GlobalAvgPool1D\n",
    "from tensorflow.keras.initializers import zeros\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def ResConv(x, kernel=(3, 3), depth=32, maxpool=False):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if maxpool :\n",
    "        x = MaxPool2D()(x)\n",
    "    x = Conv2D(depth, kernel, padding='same', use_bias=False)(x)\n",
    "    return x\n",
    "\n",
    "def ResUnit(x, depth=32, maxpool=False):\n",
    "    x = ResConv(x, depth=depth, maxpool=maxpool)\n",
    "    x = ResConv(x, depth=depth)\n",
    "    return x\n",
    "    \n",
    "def ResNetBlock(x, nunit, depth=32, maxpool=False):\n",
    "    assert nunit > 0, \"Ensure there are at least 1 unit in the ResNet Block\"\n",
    "    nunit -= 1\n",
    "    if maxpool:\n",
    "        xskip = Conv2D(depth, (1, 1), strides=2, use_bias=False)(x)\n",
    "    else: \n",
    "        xskip = x\n",
    "    x = add([ResUnit(x, depth=depth, maxpool=maxpool), xskip])\n",
    "    if nunit >= 1:\n",
    "        nunit -= 1\n",
    "        for i in range(nunit):\n",
    "            x = add([ResUnit(x, depth=depth), x])\n",
    "        x = add([ResUnit(x, depth=depth), x])\n",
    "    return x\n",
    "\n",
    "# Returns latent vector of 32 bytes\n",
    "def ResNet9(x):\n",
    "    x = Conv2D(64, (7, 7), strides=2, padding='same', use_bias=False)(x)\n",
    "    x = MaxPool2D((3, 3),  strides=2, padding='same')(x)\n",
    "    \n",
    "    nunits   = (2, 3, 2)\n",
    "    maxpools = (False, True, True)\n",
    "    depths   = (64, 32, 32)\n",
    "    \n",
    "    for i in range(3):\n",
    "        x = ResNetBlock(x, nunits[i], depth=depths[i], maxpool=maxpools[i])\n",
    "    x = GlobalAvgPool2D()(x)\n",
    "    return x\n",
    "\n",
    "#def D_init():\n",
    "#    xin = Input(shape=(64, 64, 3))\n",
    "#    x = ResNet9(xin)\n",
    "#    x = Dense(1, use_bias=False, activation='sigmoid')(x)\n",
    "#    return Model(xin, x)\n",
    "\n",
    "def Q_init():\n",
    "    xin = Input(shape=(64, 64, 3))\n",
    "    x = ResNet9(xin)\n",
    "    x = Dense(1, use_bias=False, activation='sigmoid')(x)\n",
    "    return Model(xin, x)\n",
    "\n",
    "\n",
    "def D_init():\n",
    "    xin = Input(shape=(64, 64, 3))\n",
    "    x = ResNet9(xin)\n",
    "    x = Dense(1, use_bias=False, activation='sigmoid')(x)\n",
    "    return Model(xin, x)\n",
    "\n",
    "\n",
    "#    xin = Input(shape=(64, 64, 3))\n",
    "#    x = Conv2D(8,(7, 7), use_bias=False, kernel_regularizer=regularizers.l2(0.01), padding='same')(xin)\n",
    "#    x = BatchNormalization()(x)\n",
    "#    x = Activation('relu')(x)\n",
    "#    x = MaxPool2D(2,2)(x)\n",
    "#    x = Conv2D(8,(7, 7), use_bias=False, kernel_regularizer=regularizers.l2(0.01), padding='same')(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "#    x = Activation('relu')(x)\n",
    "#    x = MaxPool2D(2,2)(x)\n",
    "#    x = Conv2D(1,(7, 7), use_bias=False, kernel_regularizer=regularizers.l2(0.01), padding='same')(x)\n",
    "#    x = BatchNormalization()(x)\n",
    "#    x = Activation('relu')(x)\n",
    "#    x = GlobalAvgPool2D()(x)\n",
    "#    x = Flatten()(x)\n",
    "#    x = Activation('sigmoid')(x)\n",
    "#    return Model(xin, x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import UpSampling2D, Reshape, Conv2DTranspose\n",
    "\n",
    "def InvResConv(x, kernel=(3, 3), depth=32, upscale=False):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if upscale :\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2D(depth, kernel, padding='same', use_bias=False)(x)\n",
    "    return x\n",
    "\n",
    "def InvResUnit(x, depth=32, upscale=False):\n",
    "    x = InvResConv(x, depth=depth)\n",
    "    x = InvResConv(x, depth=depth, upscale=upscale)\n",
    "    return x\n",
    "    \n",
    "def InvResNetBlock(x, nunit, depth=32, upscale=False):\n",
    "    assert nunit > 0, \"Ensure there are at least 1 unit in the ResNet Block\"\n",
    "    nunit -= 1\n",
    "    x = InvResUnit(x, depth=depth, upscale=upscale)\n",
    "    if nunit >= 1:\n",
    "        nunit -= 1\n",
    "        for i in range(nunit):\n",
    "            x = InvResUnit(x, depth=depth)\n",
    "        x = InvResUnit(x, depth=depth)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InvResNet9(x, size=(4,4)):\n",
    "    depths   = (32, 32, 64)\n",
    "    upscales = (True, True, False)\n",
    "    nunits   = (2, 3, 2)\n",
    "\n",
    "    x = UpSampling2D(size)(x)\n",
    "    for i in range(3):\n",
    "        x = InvResNetBlock(x, nunits[i], depth=depths[i], upscale=upscales[i])\n",
    "    x = UpSampling2D((2,2))(x)\n",
    "    x = Conv2DTranspose(3, (7, 7), strides=2, padding='same', use_bias=False)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_init():\n",
    "    xin = Input(shape=(32,), name=\"Input\")\n",
    "    x = Reshape((1,1,32))(xin)\n",
    "    x = InvResNet9(x)\n",
    "    x = Activation('relu')(x)\n",
    "    model = Model(xin, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPClHV_yKfSx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = 8 #int(np.sqrt(s / r))\n",
    "            h = 8 #int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = 0.0 #np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        fill_mode = 'constant',\n",
    "        cval=0,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=8,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=8,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        preprocessing_function=get_random_eraser(v_l=min_pix, v_h=max_pix, pixel_level=False)\n",
    ")\n",
    "datagen.fit(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzXg6VXY0fbU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result)\n",
    "    true_class = np.argmax(test_y)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['bacc'])+1),model_history.history['bacc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_bacc'])+1),model_history.history['val_bacc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['bacc'])+1),len(model_history.history['bacc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/sambit/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 64)   36864       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 64)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 64)   0           conv2d_2[0][0]                   \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 64)   36864       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 64)   0           conv2d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 32)     18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 8, 32)     128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 32)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 32)     9216        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 32)     2048        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 32)     0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 32)     128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 32)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 32)     9216        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 32)     128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 32)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 32)     9216        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 32)     0           conv2d_9[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 32)     128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 32)     9216        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 32)     128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 32)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 32)     9216        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 32)     0           conv2d_11[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 32)     128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 32)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 32)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 32)     9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 32)     128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 32)     9216        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 32)     1024        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 32)     0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 32)     128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 32)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 32)     9216        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 32)     128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 32)     9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 32)     0           conv2d_16[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 32)           0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            32          global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 263,776\n",
      "Trainable params: 262,560\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "WT_DECAY   = 1e-5\n",
    "MOMENTUM   = 0.90\n",
    "LEARNING_RATE = 0.002\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def l2_weights(model):\n",
    "    l2 = 0\n",
    "    for layer in model.layers: \n",
    "        if isinstance(layer, Model):\n",
    "            continue\n",
    "        wt = layer.weights\n",
    "        if len(wt) > 0:\n",
    "            l2 += K.sum(K.pow(wt, 2))\n",
    "    return l2\n",
    "\n",
    "def reg_loss(model):\n",
    "    def rloss(y_true, y_pred):\n",
    "        return WT_DECAY*l2_weights(model)\n",
    "    return rloss\n",
    "\n",
    "def loss_with_regularization(model):\n",
    "    def loss(y_true, y_pred):\n",
    "        return binary_crossentropy(y_true, y_pred, True) + reg_loss(model)(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bacc(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred > 0.5, dtype=y_true.dtype)\n",
    "    return K.mean(K.equal(y_true, y_pred), axis=-1)\n",
    "\n",
    "Q = Q_init()\n",
    "optimizer = SGD(lr=LEARNING_RATE, momentum=MOMENTUM, nesterov=True)\n",
    "Q.compile(optimizer=optimizer, loss=loss_with_regularization(Q), metrics=[bacc, reg_loss(Q)])\n",
    "Q.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   9408        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   36864       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   36864       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 64)   0           conv2d_19[0][0]                  \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   36864       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   36864       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 64)   0           conv2d_21[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 32)     18432       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 32)     128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 32)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 32)     9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 32)     2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 32)     0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 32)     128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 32)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 32)     9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 32)     128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 32)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 32)     9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 32)     0           conv2d_26[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 32)     128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 32)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 32)     9216        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 32)     128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 32)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 32)     9216        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 32)     0           conv2d_28[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 32)     128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 32)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 32)     0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 32)     9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 32)     128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 32)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 32)     9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 32)     1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 32)     0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 32)     128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 32)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 4, 4, 32)     9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 32)     128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 32)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 4, 4, 32)     9216        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 4, 4, 32)     0           conv2d_33[0][0]                  \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 32)           0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            32          global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 263,776\n",
      "Trainable params: 262,560\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D = D_init()\n",
    "D.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 4, 4, 32)          9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 8, 8, 32)          9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 32)          9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 8, 8, 32)          9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 32)          9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 16, 16, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 64, 64, 3)         9408      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 232,768\n",
      "Trainable params: 231,680\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G = G_init()\n",
    "\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(model):\n",
    "    def gloss(y_true, y_pred):\n",
    "        return binary_crossentropy(y_true, y_pred) + 1e-3*l2_weights(model)\n",
    "    return gloss\n",
    "    \n",
    "def define_gan(g_model, d_model, q_model):\n",
    "    d_model.trainable = False\n",
    "    q_model.trainable = False\n",
    "    d_output = d_model(g_model.output)\n",
    "    q_output = q_model(g_model.output)\n",
    "    gan = Model(g_model.input, [d_output, q_output])\n",
    "    #opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gan.compile(loss=[gan_loss(gan), 'binary_crossentropy'], optimizer='adam', metrics=['acc'])\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Count #####  0\n",
      "67/67 [==============================] - 0s 303us/sample - loss: 0.6693 - bacc: 0.6866 - rloss: 0.0253\n",
      "[0.6692899977093312, 0.6865672, 0.025288379]\n",
      "1350/1350 [==============================] - 0s 264us/sample - loss: 0.9889 - acc: 0.4956\n",
      "[0.9888695262979578, 0.49555555]\n",
      "1350/1350 [==============================] - 0s 146us/sample - loss: 12.4398 - acc: 0.5037\n",
      "[12.43978571150038, 0.5037037]\n",
      "1350/1350 [==============================] - 0s 144us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194035847982, 0.60444444]\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "67/67 [==============================] - 1s 9ms/sample - loss: 2.3615 - model_1_loss: 1.1148 - model_loss: 0.8830 - model_1_acc: 1.0000 - model_acc: 0.6567\n",
      "[2.361523414725688, 1.114797, 0.8829722, 1.0, 0.6567164]\n",
      "Iteration Count #####  1\n",
      "67/67 [==============================] - 0s 309us/sample - loss: 0.7091 - bacc: 0.6418 - rloss: 0.0294\n",
      "[0.70913951432527, 0.64179105, 0.029427836]\n",
      "1350/1350 [==============================] - 0s 111us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194007640886, 0.60444444]\n",
      "67/67 [==============================] - 1s 9ms/sample - loss: 2.4782 - model_1_loss: 0.6630 - model_loss: 1.2676 - model_1_acc: 1.0000 - model_acc: 0.5970\n",
      "[2.4781663400023732, 0.662963, 1.2676297, 1.0, 0.5970149]\n",
      "Iteration Count #####  2\n",
      "67/67 [==============================] - 0s 306us/sample - loss: 0.6853 - bacc: 0.6716 - rloss: 0.0362\n",
      "[0.6853434376752199, 0.67164177, 0.03621591]\n",
      "1350/1350 [==============================] - 0s 112us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194007590965, 0.60444444]\n",
      "67/67 [==============================] - 1s 10ms/sample - loss: 1.5985 - model_1_loss: 0.4677 - model_loss: 0.7984 - model_1_acc: 1.0000 - model_acc: 0.6418\n",
      "[1.5984808927151695, 0.46769103, 0.7984404, 1.0, 0.64179105]\n",
      "Iteration Count #####  3\n",
      "67/67 [==============================] - 0s 295us/sample - loss: 0.7004 - bacc: 0.7463 - rloss: 0.0435\n",
      "[0.7004260789992204, 0.74626863, 0.043459598]\n",
      "1350/1350 [==============================] - 0s 114us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194015663535, 0.60444444]\n",
      "67/67 [==============================] - 1s 11ms/sample - loss: 1.8939 - model_1_loss: 0.3946 - model_loss: 1.0466 - model_1_acc: 1.0000 - model_acc: 0.6269\n",
      "[1.8938652152445778, 0.3946412, 1.0466355, 1.0, 0.6268657]\n",
      "Iteration Count #####  4\n",
      "67/67 [==============================] - 0s 344us/sample - loss: 0.6962 - bacc: 0.7313 - rloss: 0.0508\n",
      "[0.6961786124243665, 0.73134327, 0.050833117]\n",
      "1350/1350 [==============================] - 0s 116us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.4071940076382474, 0.60444444]\n",
      "67/67 [==============================] - 1s 11ms/sample - loss: 1.9608 - model_1_loss: 0.7492 - model_loss: 0.8549 - model_1_acc: 1.0000 - model_acc: 0.6716\n",
      "[1.9607657007317045, 0.749239, 0.8548792, 1.0, 0.67164177]\n",
      "Iteration Count #####  5\n",
      "67/67 [==============================] - 0s 358us/sample - loss: 0.7494 - bacc: 0.6418 - rloss: 0.0561\n",
      "[0.7493580526380397, 0.64179105, 0.05614257]\n",
      "1350/1350 [==============================] - 0s 121us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194007590965, 0.60444444]\n",
      "67/67 [==============================] - 1s 12ms/sample - loss: 2.4310 - model_1_loss: 0.6721 - model_loss: 1.2276 - model_1_acc: 1.0000 - model_acc: 0.7164\n",
      "[2.430968249022071, 0.672051, 1.2276281, 1.0, 0.7164179]\n",
      "Iteration Count #####  6\n",
      "67/67 [==============================] - 0s 347us/sample - loss: 0.7311 - bacc: 0.6418 - rloss: 0.0615\n",
      "[0.7311093006561051, 0.64179105, 0.06146154]\n",
      "1350/1350 [==============================] - 0s 118us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194007590965, 0.60444444]\n",
      "67/67 [==============================] - 1s 13ms/sample - loss: 2.3126 - model_1_loss: 0.6214 - model_loss: 1.1808 - model_1_acc: 1.0000 - model_acc: 0.6866\n",
      "[2.3126382525287457, 0.62142843, 1.1807979, 1.0, 0.6865672]\n",
      "Iteration Count #####  7\n",
      "67/67 [==============================] - 0s 306us/sample - loss: 0.7295 - bacc: 0.6567 - rloss: 0.0644\n",
      "[0.729513596687744, 0.6567164, 0.06437013]\n",
      "1350/1350 [==============================] - 0s 121us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.4071940075928677, 0.60444444]\n",
      "67/67 [==============================] - 1s 14ms/sample - loss: 2.5971 - model_1_loss: 0.5911 - model_loss: 1.4002 - model_1_acc: 1.0000 - model_acc: 0.6866\n",
      "[2.597115603845511, 0.5911404, 1.4001651, 1.0, 0.6865672]\n",
      "Iteration Count #####  8\n",
      "67/67 [==============================] - 0s 314us/sample - loss: 0.7287 - bacc: 0.6866 - rloss: 0.0703\n",
      "[0.7286690184429511, 0.6865672, 0.070250124]\n",
      "1350/1350 [==============================] - 0s 124us/sample - loss: 3.4072 - acc: 0.6044\n",
      "[3.407194007633295, 0.60444444]\n",
      "67/67 [==============================] - 1s 14ms/sample - loss: 3.7785 - model_1_loss: 2.6333 - model_loss: 0.7973 - model_1_acc: 1.0000 - model_acc: 0.8060\n",
      "[3.778480511992725, 2.6332846, 0.7972657, 1.0, 0.80597013]\n",
      "Iteration Count #####  9\n",
      "67/67 [==============================] - 0s 418us/sample - loss: 0.7341 - bacc: 0.7015 - rloss: 0.0737\n",
      "[0.7341400647341315, 0.70149255, 0.07367429]\n",
      "1350/1350 [==============================] - 0s 132us/sample - loss: 3.4500 - acc: 0.6044\n",
      "[3.4499969974270575, 0.60444444]\n",
      "67/67 [==============================] - 1s 15ms/sample - loss: 4.6928 - model_1_loss: 3.6517 - model_loss: 0.7293 - model_1_acc: 1.0000 - model_acc: 0.7015\n",
      "[4.692820997380498, 3.651661, 0.72928923, 1.0, 0.70149255]\n",
      "Iteration Count #####  10\n",
      "67/67 [==============================] - 0s 288us/sample - loss: 0.7130 - bacc: 0.7313 - rloss: 0.0764\n",
      "[0.7129557822177659, 0.73134327, 0.076387145]\n",
      "1350/1350 [==============================] - 0s 133us/sample - loss: 3.4077 - acc: 0.6044\n",
      "[3.4077032933599765, 0.60444444]\n",
      "67/67 [==============================] - 1s 16ms/sample - loss: 8.8169 - model_1_loss: 7.7426 - model_loss: 0.7564 - model_1_acc: 0.0000e+00 - model_acc: 0.7612\n",
      "[8.816902915043617, 7.7426033, 0.756408, 0.0, 0.76119405]\n",
      "Iteration Count #####  11\n",
      "67/67 [==============================] - 0s 278us/sample - loss: 0.7442 - bacc: 0.6567 - rloss: 0.0857\n",
      "[0.7442180265241595, 0.6567164, 0.0857209]\n",
      "1350/1350 [==============================] - 0s 130us/sample - loss: 5.4529 - acc: 0.1044\n",
      "[5.452906241240325, 0.104444444]\n",
      "1350/1350 [==============================] - 0s 153us/sample - loss: 13.4763 - acc: 0.5000\n",
      "[13.476273697747125, 0.5]\n",
      "1350/1350 [==============================] - 0s 150us/sample - loss: 0.0682 - acc: 1.0000\n",
      "[0.06819453707447759, 1.0]\n",
      "67/67 [==============================] - 1s 17ms/sample - loss: 17.2886 - model_1_loss: 15.5244 - model_loss: 1.0904 - model_1_acc: 0.0000e+00 - model_acc: 0.7463\n",
      "[17.28855646902056, 15.524392, 1.0904399, 0.0, 0.74626863]\n",
      "Iteration Count #####  12\n",
      "67/67 [==============================] - 0s 338us/sample - loss: 0.7380 - bacc: 0.6866 - rloss: 0.0895\n",
      "[0.7379788751922437, 0.6865672, 0.08945828]\n",
      "1350/1350 [==============================] - 0s 138us/sample - loss: 6.1182 - acc: 0.5000\n",
      "[6.118168779375653, 0.5]\n",
      "1350/1350 [==============================] - 0s 161us/sample - loss: 0.0377 - acc: 1.0000\n",
      "[0.03765977974843096, 1.0]\n",
      "67/67 [==============================] - 1s 17ms/sample - loss: 5.4526 - model_1_loss: 4.1191 - model_loss: 0.9067 - model_1_acc: 0.6269 - model_acc: 0.7313\n",
      "[5.452561136501939, 4.1190567, 0.90671927, 0.6268657, 0.73134327]\n",
      "Iteration Count #####  13\n",
      "67/67 [==============================] - 0s 284us/sample - loss: 0.7659 - bacc: 0.6269 - rloss: 0.0925\n",
      "[0.7659434645033595, 0.6268657, 0.092536785]\n",
      "1350/1350 [==============================] - 0s 144us/sample - loss: 0.2943 - acc: 0.7963\n",
      "[0.29425314121362234, 0.7962963]\n",
      "67/67 [==============================] - 1s 18ms/sample - loss: 7.7946 - model_1_loss: 6.2941 - model_loss: 0.9799 - model_1_acc: 0.0000e+00 - model_acc: 0.7463\n",
      "[7.79458250928281, 6.2941318, 0.97994965, 0.0, 0.74626863]\n",
      "Iteration Count #####  14\n",
      "67/67 [==============================] - 0s 295us/sample - loss: 0.7928 - bacc: 0.6418 - rloss: 0.0992\n",
      "[0.7928091372126964, 0.64179105, 0.09919598]\n",
      "1350/1350 [==============================] - 0s 146us/sample - loss: 1.4014 - acc: 0.5000\n",
      "[1.4013895599447466, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350/1350 [==============================] - 0s 165us/sample - loss: 0.0292 - acc: 1.0000\n",
      "[0.02924386503243888, 1.0]\n",
      "67/67 [==============================] - 1s 19ms/sample - loss: 5.3097 - model_1_loss: 3.6135 - model_loss: 1.1838 - model_1_acc: 1.0000 - model_acc: 0.7463\n",
      "[5.309658029186192, 3.613477, 1.1838018, 1.0, 0.74626863]\n",
      "Iteration Count #####  15\n",
      "67/67 [==============================] - 0s 331us/sample - loss: 0.7649 - bacc: 0.6866 - rloss: 0.1002\n",
      "[0.7649452882026558, 0.6865672, 0.10020178]\n",
      "1350/1350 [==============================] - 0s 141us/sample - loss: 5.6778e-04 - acc: 1.0000\n",
      "[0.0005677777325682756, 1.0]\n",
      "67/67 [==============================] - 1s 20ms/sample - loss: 5.2665 - model_1_loss: 3.5852 - model_loss: 1.1736 - model_1_acc: 1.0000 - model_acc: 0.7761\n",
      "[5.266549245635075, 3.5852134, 1.1735594, 1.0, 0.7761194]\n",
      "Iteration Count #####  16\n",
      "67/67 [==============================] - 0s 352us/sample - loss: 0.7650 - bacc: 0.6716 - rloss: 0.1066\n",
      "[0.7649789781712774, 0.67164177, 0.10664905]\n",
      "1350/1350 [==============================] - 0s 153us/sample - loss: 3.2083e-04 - acc: 1.0000\n",
      "[0.0003208334973357894, 1.0]\n",
      "67/67 [==============================] - 1s 21ms/sample - loss: 4.6436 - model_1_loss: 3.6075 - model_loss: 0.7259 - model_1_acc: 1.0000 - model_acc: 0.7761\n",
      "[4.64355696848969, 3.6074607, 0.725898, 1.0, 0.7761194]\n",
      "Iteration Count #####  17\n",
      "67/67 [==============================] - 0s 286us/sample - loss: 0.7780 - bacc: 0.6716 - rloss: 0.1095\n",
      "[0.7780125012148672, 0.67164177, 0.109541856]\n",
      "1350/1350 [==============================] - 0s 143us/sample - loss: 4.2252e-04 - acc: 1.0000\n",
      "[0.0004225243450599481, 1.0]\n",
      "67/67 [==============================] - 1s 21ms/sample - loss: 5.2473 - model_1_loss: 3.6653 - model_loss: 1.1025 - model_1_acc: 1.0000 - model_acc: 0.7164\n",
      "[5.247287629255608, 3.6653016, 1.1024727, 1.0, 0.7164179]\n",
      "Iteration Count #####  18\n",
      "67/67 [==============================] - 0s 377us/sample - loss: 0.7633 - bacc: 0.7015 - rloss: 0.1134\n",
      "[0.7633066284122751, 0.70149255, 0.11338214]\n",
      "1350/1350 [==============================] - 0s 154us/sample - loss: 0.0273 - acc: 1.0000\n",
      "[0.027345465804553694, 1.0]\n",
      "67/67 [==============================] - 1s 22ms/sample - loss: 5.4197 - model_1_loss: 3.5854 - model_loss: 1.3187 - model_1_acc: 1.0000 - model_acc: 0.7612\n",
      "[5.419676649036692, 3.5853665, 1.3186728, 1.0, 0.76119405]\n",
      "Iteration Count #####  19\n",
      "67/67 [==============================] - 0s 354us/sample - loss: 0.7706 - bacc: 0.6866 - rloss: 0.1127\n",
      "[0.770640641450882, 0.6865672, 0.11268125]\n",
      "1350/1350 [==============================] - 0s 150us/sample - loss: 3.2115e-04 - acc: 1.0000\n",
      "[0.00032114991394472005, 1.0]\n",
      "67/67 [==============================] - 2s 23ms/sample - loss: 5.1413 - model_1_loss: 3.6065 - model_loss: 1.0725 - model_1_acc: 1.0000 - model_acc: 0.7761\n",
      "[5.1413243777716335, 3.6064548, 1.0724527, 1.0, 0.7761194]\n",
      "Iteration Count #####  20\n",
      "67/67 [==============================] - 0s 337us/sample - loss: 0.7752 - bacc: 0.6567 - rloss: 0.1191\n",
      "[0.7751900188958467, 0.6567164, 0.11911792]\n",
      "1350/1350 [==============================] - 0s 153us/sample - loss: 0.0035 - acc: 1.0000\n",
      "[0.0034790877411486924, 1.0]\n",
      "67/67 [==============================] - 2s 24ms/sample - loss: 8.4288 - model_1_loss: 4.1724 - model_loss: 3.1265 - model_1_acc: 0.7910 - model_acc: 0.6567\n",
      "[8.428815272317005, 4.1724153, 3.1264937, 0.7910448, 0.6567164]\n",
      "Iteration Count #####  21\n",
      "67/67 [==============================] - 0s 351us/sample - loss: 0.7866 - bacc: 0.7015 - rloss: 0.1220\n",
      "[0.786569960526566, 0.70149255, 0.12203788]\n",
      "1350/1350 [==============================] - 0s 146us/sample - loss: 0.2960 - acc: 0.8696\n",
      "[0.2959556654944188, 0.8696296]\n",
      "67/67 [==============================] - 2s 25ms/sample - loss: 7.5522 - model_1_loss: 3.6061 - model_loss: 2.7540 - model_1_acc: 1.0000 - model_acc: 0.5821\n",
      "[7.552193944133929, 3.6061366, 2.7540188, 1.0, 0.58208954]\n",
      "Iteration Count #####  22\n",
      "67/67 [==============================] - 0s 359us/sample - loss: 0.7662 - bacc: 0.7164 - rloss: 0.1238\n",
      "[0.7661652387078128, 0.7164179, 0.123788506]\n",
      "1350/1350 [==============================] - 0s 163us/sample - loss: 0.0025 - acc: 1.0000\n",
      "[0.0025434621878796153, 1.0]\n",
      "67/67 [==============================] - 2s 25ms/sample - loss: 5.8238 - model_1_loss: 3.5673 - model_loss: 1.8027 - model_1_acc: 1.0000 - model_acc: 0.6866\n",
      "[5.823784707197502, 3.567316, 1.8027152, 1.0, 0.6865672]\n",
      "Iteration Count #####  23\n",
      "67/67 [==============================] - 0s 353us/sample - loss: 0.7928 - bacc: 0.6716 - rloss: 0.1222\n",
      "[0.7928322393502762, 0.67164177, 0.122150816]\n",
      "1350/1350 [==============================] - 0s 166us/sample - loss: 6.0564e-04 - acc: 1.0000\n",
      "[0.0006056397826479817, 1.0]\n",
      "67/67 [==============================] - 2s 26ms/sample - loss: 5.2321 - model_1_loss: 3.6164 - model_loss: 1.1301 - model_1_acc: 1.0000 - model_acc: 0.7164\n",
      "[5.23205859981366, 3.6164038, 1.130089, 1.0, 0.7164179]\n",
      "Iteration Count #####  24\n",
      "67/67 [==============================] - 0s 360us/sample - loss: 0.7788 - bacc: 0.7015 - rloss: 0.1280\n",
      "[0.7787658398720756, 0.70149255, 0.12801659]\n",
      "1350/1350 [==============================] - 0s 139us/sample - loss: 0.0081 - acc: 1.0000\n",
      "[0.008065935082871605, 1.0]\n",
      "67/67 [==============================] - 2s 27ms/sample - loss: 5.8552 - model_1_loss: 3.6430 - model_loss: 1.5420 - model_1_acc: 1.0000 - model_acc: 0.7164\n",
      "[5.855187469453954, 3.6429777, 1.542027, 1.0, 0.7164179]\n",
      "Iteration Count #####  25\n",
      "67/67 [==============================] - 0s 339us/sample - loss: 0.7561 - bacc: 0.7612 - rloss: 0.1269\n",
      "[0.7560803316422363, 0.76119405, 0.12688991]\n",
      "1350/1350 [==============================] - 0s 182us/sample - loss: 0.0299 - acc: 1.0000\n",
      "[0.029924294051058866, 1.0]\n",
      "67/67 [==============================] - 2s 29ms/sample - loss: 14.8350 - model_1_loss: 11.7763 - model_loss: 2.0201 - model_1_acc: 0.0000e+00 - model_acc: 0.6418\n",
      "[14.835018414169994, 11.776329, 2.0200775, 0.0, 0.64179105]\n",
      "Iteration Count #####  26\n",
      "67/67 [==============================] - 0s 377us/sample - loss: 0.7787 - bacc: 0.7015 - rloss: 0.1307\n",
      "[0.7786883022358169, 0.70149255, 0.13072097]\n",
      "1350/1350 [==============================] - 0s 185us/sample - loss: 4.1979 - acc: 0.5000\n",
      "[4.197856923592173, 0.5]\n",
      "1350/1350 [==============================] - 0s 190us/sample - loss: 0.2438 - acc: 0.8896\n",
      "[0.24378946904782894, 0.8896296]\n",
      "67/67 [==============================] - 2s 29ms/sample - loss: 5.9110 - model_1_loss: 3.6165 - model_loss: 1.6017 - model_1_acc: 1.0000 - model_acc: 0.7612\n",
      "[5.910977505925876, 3.61648, 1.6017, 1.0, 0.76119405]\n",
      "Iteration Count #####  27\n",
      "67/67 [==============================] - 0s 395us/sample - loss: 0.8091 - bacc: 0.6418 - rloss: 0.1326\n",
      "[0.8091431589268926, 0.64179105, 0.13263014]\n",
      "1350/1350 [==============================] - 0s 186us/sample - loss: 0.0028 - acc: 1.0000\n",
      "[0.0027577457746007926, 1.0]\n",
      "67/67 [==============================] - 2s 29ms/sample - loss: 5.5785 - model_1_loss: 3.5749 - model_loss: 1.3981 - model_1_acc: 1.0000 - model_acc: 0.7015\n",
      "[5.578496758617572, 3.5749352, 1.3980817, 1.0, 0.70149255]\n",
      "Iteration Count #####  28\n",
      "67/67 [==============================] - 0s 389us/sample - loss: 0.8172 - bacc: 0.6418 - rloss: 0.1315\n",
      "[0.8172102397057548, 0.64179105, 0.13150589]\n",
      "1350/1350 [==============================] - 0s 173us/sample - loss: 0.0044 - acc: 1.0000\n",
      "[0.004352736154019281, 1.0]\n",
      "67/67 [==============================] - 2s 30ms/sample - loss: 5.4895 - model_1_loss: 3.5490 - model_loss: 1.3543 - model_1_acc: 1.0000 - model_acc: 0.6716\n",
      "[5.489517094484016, 3.5490408, 1.3542995, 1.0, 0.67164177]\n",
      "Iteration Count #####  29\n",
      "67/67 [==============================] - 0s 372us/sample - loss: 0.8100 - bacc: 0.6716 - rloss: 0.1373\n",
      "[0.8099755884996102, 0.67164177, 0.1372592]\n",
      "1350/1350 [==============================] - 0s 177us/sample - loss: 2.6908e-04 - acc: 1.0000\n",
      "[0.000269081313486418, 1.0]\n",
      "67/67 [==============================] - 2s 31ms/sample - loss: 5.4989 - model_1_loss: 3.6050 - model_loss: 1.3221 - model_1_acc: 1.0000 - model_acc: 0.7313\n",
      "[5.4989420513608565, 3.604951, 1.3221127, 1.0, 0.73134327]\n",
      "Iteration Count #####  30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 368us/sample - loss: 0.7951 - bacc: 0.7015 - rloss: 0.1410\n",
      "[0.7951427840474826, 0.70149255, 0.14097361]\n",
      "1350/1350 [==============================] - 0s 188us/sample - loss: 0.0090 - acc: 1.0000\n",
      "[0.008994016993307957, 1.0]\n",
      "67/67 [==============================] - 2s 32ms/sample - loss: 9.6756 - model_1_loss: 3.6028 - model_loss: 7.1649 - model_1_acc: 1.0000 - model_acc: 0.5522\n",
      "[9.675619993636857, 3.602789, 7.164889, 1.0, 0.5522388]\n",
      "Iteration Count #####  31\n",
      "67/67 [==============================] - 0s 355us/sample - loss: 0.7876 - bacc: 0.7015 - rloss: 0.1404\n",
      "[0.7876449240677392, 0.70149255, 0.14041826]\n",
      "1350/1350 [==============================] - 0s 193us/sample - loss: 0.0064 - acc: 1.0000\n",
      "[0.006355766929617083, 1.0]\n",
      "67/67 [==============================] - 2s 35ms/sample - loss: 5.1837 - model_1_loss: 3.6334 - model_loss: 1.0811 - model_1_acc: 1.0000 - model_acc: 0.7015\n",
      "[5.1836625390978, 3.6333704, 1.0810503, 1.0, 0.70149255]\n",
      "Iteration Count #####  32\n",
      "67/67 [==============================] - 0s 419us/sample - loss: 0.8093 - bacc: 0.6866 - rloss: 0.1446\n",
      "[0.8093020546792159, 0.6865672, 0.14460011]\n",
      "1350/1350 [==============================] - 0s 207us/sample - loss: 0.0306 - acc: 1.0000\n",
      "[0.030611314807708064, 1.0]\n",
      "67/67 [==============================] - 2s 35ms/sample - loss: 4.5012 - model_1_loss: 3.9621 - model_loss: 0.4833 - model_1_acc: 1.0000 - model_acc: 0.7313\n",
      "[4.501169076606409, 3.962106, 0.4832697, 1.0, 0.73134327]\n",
      "Iteration Count #####  33\n",
      "67/67 [==============================] - 0s 409us/sample - loss: 0.7863 - bacc: 0.7313 - rloss: 0.1476\n",
      "[0.786258337657843, 0.73134327, 0.14764616]\n",
      "1350/1350 [==============================] - 0s 196us/sample - loss: 0.1893 - acc: 1.0000\n",
      "[0.18932139843805795, 1.0]\n",
      "67/67 [==============================] - 2s 35ms/sample - loss: 7.1201 - model_1_loss: 3.5961 - model_loss: 2.7862 - model_1_acc: 1.0000 - model_acc: 0.5522\n",
      "[7.120147121486379, 3.5960667, 2.7861893, 1.0, 0.5522388]\n",
      "Iteration Count #####  34\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "mcp = ModelCheckpoint(\"q.hf5\", monitor='val_bacc', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "class MyEarlyStopping(Callback):\n",
    "    def __init__(self, size):\n",
    "        self.baseline = size*0.5\n",
    "        super().__init__()\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.correct  = 0\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.correct += logs['size']*logs['acc']\n",
    "        if self.correct > self.baseline:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"Iteration Count ##### \", i)\n",
    "    Q.fit_generator(datagen.flow(trainX, trainY, batch_size=BATCH_SIZE), epochs=100, shuffle=True, \n",
    "                    validation_data=(testX, testY), callbacks=[mcp], verbose=0)\n",
    "    \n",
    "    qres = Q.evaluate(testX, testY)\n",
    "    print(qres)\n",
    "    \n",
    "    Q.save_weights(\"qb.hf5\")\n",
    "    \n",
    "    Q.load_weights(\"q.hf5\")\n",
    "    \n",
    "\n",
    "    func = K.function(Q.input, Q.layers[-2].output)\n",
    "    Gtrain, Gval = func(trainX), func(testX)\n",
    "    \n",
    "    fake = np.random.randn(*trainX.shape) if i == 0 else K.function(gan.input, G.output)(Gtrain)\n",
    "\n",
    "    Dx = np.append(trainX, fake, axis=0)\n",
    "    Dy = np.append(np.ones((trainX.shape[0],)), np.zeros((fake.shape[0],)))\n",
    "    \n",
    "\n",
    "    dres = D.evaluate(Dx, Dy)\n",
    "    print(dres)\n",
    "\n",
    "    count = 0 \n",
    "    while dres[1] < 0.60 and count < 20:\n",
    "        s = np.arange(Dx.shape[0])\n",
    "        np.random.shuffle(s)\n",
    "        Dx, Dy = Dx[s], Dy[s]\n",
    "        D.fit(Dx, Dy, epochs=1, batch_size=32, \n",
    "              validation_data=(testX, np.ones((testX.shape[0],))), callbacks=[MyEarlyStopping(len(Dx))], verbose=0)\n",
    "        dres = D.evaluate(Dx, Dy)\n",
    "        count += 1\n",
    "        print(dres)\n",
    "    \n",
    "    gan = define_gan(G, D, Q)\n",
    "    Q.trainable = True\n",
    "    \n",
    "    gan.fit(Gtrain, [np.zeros((Gtrain.shape[0],)), trainY], batch_size=BATCH_SIZE, epochs=100, verbose=0)\n",
    "    \n",
    "    gres = gan.evaluate(Gval, [np.zeros((Gval.shape[0],)), testY])\n",
    "    \n",
    "    print(gres)\n",
    "    \n",
    "    Q.load_weights(\"qb.hf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function(Q.input, Q.layers[-2].output)\n",
    "Gtrain, Gval = func(trainX), func(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func1 = K.function(G.input, G.output)\n",
    "testfake = func1(Gval)\n",
    "len(testfake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment-19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

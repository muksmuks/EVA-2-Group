{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Assignment-19.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVY3XJhuhvkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "3d310999-c876-44e0-d393-79863465aeeb"
      },
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    import os\n",
        "    os.chdir('/content')\n",
        "    if not os.path.isdir('/content/EVA-2-Group/'):\n",
        "        !git clone https://github.com/sambitdash/EVA-2-Group.git\n",
        "    os.chdir('/content/EVA-2-Group/Session-19')\n",
        "    !pwd\n",
        "    \n",
        "    !git config user.email \"sambitdash@gmail.com\"\n",
        "    !git config user.name \"Sambit Kumar Dash\"\n",
        "    !git config user.password \"your password\"\n",
        "    !git status"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EVA-2-Group'...\n",
            "remote: Enumerating objects: 1096, done.\u001b[K\n",
            "remote: Counting objects: 100% (1096/1096), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1080/1080), done.\u001b[K\n",
            "remote: Total 2192 (delta 13), reused 1087 (delta 7), pack-reused 1096\u001b[K\n",
            "Receiving objects: 100% (2192/2192), 592.88 MiB | 35.35 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "Checking out files: 100% (2036/2036), done.\n",
            "/content/EVA-2-Group/Session-19\n",
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbhSFX9Jhvkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "\n",
        "car_types = ['hatch', 'sedan']\n",
        "\n",
        "def resize_image(img, size=(64,64)):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    if h == w: \n",
        "        return cv2.resize(img, size, cv2.INTER_AREA)\n",
        "\n",
        "    dif = h if h > w else w\n",
        "\n",
        "    interpolation = cv2.INTER_AREA if dif > (size[0]+size[1])//2 else cv2.INTER_CUBIC\n",
        "\n",
        "    x_pos = (dif - w)//2\n",
        "    y_pos = (dif - h)//2\n",
        "\n",
        "    if len(img.shape) == 2:\n",
        "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
        "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
        "    else:\n",
        "        c = img.shape[2]\n",
        "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
        "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
        "\n",
        "    return cv2.resize(mask, size, interpolation)\n",
        "\n",
        "spath, dpath = join('data', 'cars'), join('data', 'norm')\n",
        "\n",
        "if not os.path.isdir(dpath):\n",
        "    os.mkdir(dpath)\n",
        "\n",
        "for ct in car_types:\n",
        "    sp, dp = join(spath, ct), join(dpath, ct)\n",
        "    if not os.path.isdir(dp):\n",
        "        os.mkdir(dp)\n",
        "    for f in listdir(sp):\n",
        "        sf, df = join(sp, f), join(dp, f)\n",
        "        img = cv2.imread(sf)\n",
        "        img = resize_image(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        cv2.imwrite(df, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgWY9ontMgFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "from tensorflow.keras import utils \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(trainx, trainy), (testx, testy) = cifar10.load_data()\n",
        "ntrain, rows, cols, ch =  trainx.shape\n",
        "ntest, _, _, _         =  testx.shape\n",
        "ncls = len(np.unique(trainy))\n",
        "print(ncls)\n",
        "\n",
        "trainx = trainx.astype('float32') / 255\n",
        "testx = testx.astype('float32') / 255\n",
        "\n",
        "trainx_mean = trainx.mean(axis=0)\n",
        "trainx_std  = trainx.std(axis=0)\n",
        "\n",
        "#print(trainx_mean, trainx_std)\n",
        "\n",
        "datagen = ImageDataGenerator(zca_whitening=True)\n",
        "\n",
        "datagen.fit(trainx)\n",
        "\n",
        "iterate = datagen.flow(trainx, trainy, batch_size=len(trainx), shuffle=False)\n",
        "\n",
        "trainx, trainy = iterate.next()\n",
        "\n",
        "iterate = datagen.flow(testx, testy, batch_size=len(testx), shuffle=False)\n",
        "\n",
        "testx, testy = iterate.next()\n",
        "\n",
        "# trainx -= trainx_mean\n",
        "# trainx /= trainx_std\n",
        "\n",
        "# testx -= trainx_mean\n",
        "# testx /= trainx_std\n",
        "\n",
        "trainX, trainY = trainx, utils.to_categorical(trainy)\n",
        "testX,  testY  = testx,  utils.to_categorical(testy)\n",
        "\n",
        "min_pix, max_pix = trainX.min(), trainX.max()\n",
        "\n",
        "print(min_pix, max_pix)\n",
        "print(testX.min(), testX.max())\n",
        "\n",
        "print(trainX.shape, trainY.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik_4kxmzJGoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "WT_DECAY   = 1e-4\n",
        "LRFNEPOCH  = 4\n",
        "MOMENTUM   = 0.9\n",
        "EPOCHS     = 300\n",
        "LEARNING_RATE = 0.01\n",
        "ncls = 2\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation, MaxPool2D\n",
        "from tensorflow.keras.layers import add, Input, Dense, Flatten, GlobalAvgPool2D\n",
        "from tensorflow.keras.initializers import zeros\n",
        "\n",
        "def ResConv(x, kernel=(3, 3), depth=32, maxpool=False):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    if maxpool :\n",
        "        x = MaxPool2D()(x)\n",
        "    x = Conv2D(depth, kernel, padding='same', use_bias=False)(x)\n",
        "    return x\n",
        "\n",
        "def ResUnit(x, depth=32, maxpool=False):\n",
        "    x = ResConv(x, depth=depth, maxpool=maxpool)\n",
        "    x = ResConv(x, depth=depth)\n",
        "    return x\n",
        "    \n",
        "def ResNetBlock(x, nunit, depth=32, maxpool=False, name=\"Block-1\"):\n",
        "    assert nunit > 0, \"Ensure there are at least 1 unit in the ResNet Block\"\n",
        "    nunit -= 1\n",
        "    if maxpool:\n",
        "        xskip = Conv2D(depth, (1, 1), strides=2, use_bias=False)(x)\n",
        "    else: \n",
        "        xskip = x\n",
        "    x = add([ResUnit(x, depth=depth, maxpool=maxpool), xskip])\n",
        "    if nunit >= 1:\n",
        "        nunit -= 1\n",
        "        for i in range(nunit):\n",
        "            x = add([ResUnit(x, depth=depth), x])\n",
        "        x = add([ResUnit(x, depth=depth), x], name=name)\n",
        "    return x\n",
        "\n",
        "# Returns latent vector of 512 bytes        \n",
        "def ResNet18(x):\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', use_bias=False)(x)\n",
        "    x = MaxPool2D((3, 3),  strides=2, padding='same')(x)\n",
        "    \n",
        "    nunits   = (2, 2, 2, 2)\n",
        "    maxpools = (False, True, True, True)\n",
        "    depths   = (64, 128, 256, 512)\n",
        "    \n",
        "    for i in range(4):\n",
        "        x = ResNetBlock(x, nunits[i], depth=depths[i], maxpool=maxpools[i], name=\"Block-\"+str(i))\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    return x\n",
        "\n",
        "# Returns latent vector of 256 bytes\n",
        "def ResNet9(x):\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', use_bias=False)(x)\n",
        "    x = MaxPool2D((3, 3),  strides=2, padding='same')(x)\n",
        "    \n",
        "    nunits   = (2, 3, 2)\n",
        "    maxpools = (False, True, True)\n",
        "    depths   = (64, 128, 256)\n",
        "    \n",
        "    for i in range(3):\n",
        "        x = ResNetBlock(x, nunits[i], depth=depths[i], maxpool=maxpools[i], name=\"Block-\"+str(i))\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVGCyMhcK5jY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d030c9b-cf65-47d0-e852-d525bd58fa6f"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def l2_weights(model):\n",
        "    l2 = 0\n",
        "    for layer in model.layers: \n",
        "        wt = layer.weights\n",
        "        if len(wt) > 0:\n",
        "            l2 += K.sum(K.pow(wt, 2))\n",
        "    return l2\n",
        "\n",
        "def reg_loss(model):\n",
        "    def rloss(y_true, y_pred):\n",
        "        return model.l2_reg*l2_weights(model)\n",
        "    return rloss\n",
        "\n",
        "def loss_with_regularization(model):\n",
        "    def loss(y_true, y_pred):\n",
        "        return categorical_crossentropy(y_true, y_pred) + reg_loss(model)(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def model_init(optimizer=None):\n",
        "    xin = Input(shape=(64, 64, 3), name=\"Input\")\n",
        "    x = ResNet9(xin)\n",
        "    x = Dense(ncls, use_bias=False)(x)\n",
        "    y = Activation('softmax')(x)\n",
        "    model = Model(xin, y)\n",
        "    model.l2_reg = K.variable(value=WT_DECAY, dtype='float32', name='reg_loss')\n",
        "    if optimizer is None:\n",
        "        optimizer = SGD(lr=1e-3, momentum=MOMENTUM, nesterov=True)\n",
        "    model.compile(optimizer=optimizer, loss=loss_with_regularization(model), metrics=['acc', reg_loss(model)])\n",
        "    return model\n",
        "\n",
        "model = model_init()\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input (InputLayer)              [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 32, 32, 64)   9408        Input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 64)   256         max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 64)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 16, 16, 64)   36864       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 64)   256         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 16, 16, 64)   36864       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 16, 16, 64)   0           conv2d_82[0][0]                  \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 64)   256         add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 64)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 16, 16, 64)   36864       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 64)   256         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 64)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 16, 16, 64)   36864       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Block-0 (Add)                   (None, 16, 16, 64)   0           conv2d_84[0][0]                  \n",
            "                                                                 add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 64)   256         Block-0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 64)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 8, 8, 64)     0           activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 128)    73728       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 8, 8, 128)    512         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 128)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 128)    147456      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 128)    8192        Block-0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 128)    0           conv2d_87[0][0]                  \n",
            "                                                                 conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 8, 8, 128)    512         add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 128)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 128)    147456      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 128)    512         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 128)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 128)    147456      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 8, 8, 128)    0           conv2d_89[0][0]                  \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 128)    512         add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 128)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 128)    147456      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 128)    512         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 128)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 128)    147456      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Block-1 (Add)                   (None, 8, 8, 128)    0           conv2d_91[0][0]                  \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 128)    512         Block-1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 128)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 4, 4, 128)    0           activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 4, 4, 256)    294912      max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 4, 4, 256)    1024        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 256)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 4, 4, 256)    589824      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    32768       Block-1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 4, 4, 256)    0           conv2d_94[0][0]                  \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 4, 4, 256)    1024        add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 256)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    589824      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 4, 4, 256)    1024        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 256)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 256)    589824      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Block-2 (Add)                   (None, 4, 4, 256)    0           conv2d_96[0][0]                  \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 256)          0           Block-2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            512         global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 2)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,081,152\n",
            "Trainable params: 3,077,440\n",
            "Non-trainable params: 3,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPClHV_yKfSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "08b1cb6a-807b-4783-c8a2-331d47758cd8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = 8 #int(np.sqrt(s / r))\n",
        "            h = 8 #int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = 0.0 #np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        fill_mode = 'constant',\n",
        "        cval=0,\n",
        "        width_shift_range=4,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=4,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        preprocessing_function=get_random_eraser(v_l=min_pix, v_h=max_pix, pixel_level=False)\n",
        ")\n",
        "datagen.fit(trainX)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4772cc197967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mheight_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# randomly shift images vertically (fraction of total height)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mhorizontal_flip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# randomly flip images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_random_eraser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_pix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_pix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'min_pix' is not defined"
          ]
        }
      ]
    }
  ]
}